{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GcY8LQ9zqUM"
      },
      "source": [
        "### **A. Import Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0HeFqxBFzmeR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfTusMHKz6aX"
      },
      "source": [
        "### **B. Upload / access the dataset and Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liDCC0VNz24E",
        "outputId": "27717b83-5de5-4150-e996-85f190e5e6a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data ready. Input dimension: 29 features.\n",
            "Training Autoencoder on 227452 normal transactions.\n"
          ]
        }
      ],
      "source": [
        "FILE_PATH = 'creditcard.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(FILE_PATH)\n",
        "\n",
        "# 1. Separate features (X) and target (y)\n",
        "X = df.drop(['Time', 'Class'], axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# 2. Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "INPUT_DIM = X_scaled.shape[1] # Number of features = 29 (V1 to V28 + Amount)\n",
        "\n",
        "# 3. Isolate NORMAL (non-fraudulent) transactions for training and validation\n",
        "X_normal = X_scaled[y == 0]\n",
        "X_train_normal, X_val_normal = train_test_split(\n",
        "    X_normal,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Data ready. Input dimension: {INPUT_DIM} features.\")\n",
        "print(f\"Training Autoencoder on {X_train_normal.shape[0]} normal transactions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDnA6dGi0x5S"
      },
      "source": [
        "### **C. Encoder converts it into latent representation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At3qa1ra0noU",
        "outputId": "bdde8c49-c62f-4ffb-bc91-3f6d283c31e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder defined.\n"
          ]
        }
      ],
      "source": [
        "LATENT_DIM = 14     # Bottleneck size (29 / 2)\n",
        "INTERMEDIATE_DIM = 24\n",
        "\n",
        "# Define the ENCODER Network\n",
        "# Input Layer\n",
        "input_layer = Input(shape=(INPUT_DIM,), name='Input_Layer')\n",
        "\n",
        "# Compressed Layer 1\n",
        "encoded = Dense(INTERMEDIATE_DIM, activation='relu', name='Encoder_L1')(input_layer)\n",
        "\n",
        "# Latent Representation (Bottleneck)\n",
        "latent_representation = Dense(LATENT_DIM, activation='relu', name='Latent_Representation')(encoded)\n",
        "\n",
        "print(\"Encoder defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLj4F2-r1bGz"
      },
      "source": [
        "### **D. Decoder Converts Back to Original Input**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToroDC3j09qA",
        "outputId": "81a07d13-7fb0-4800-8b56-67f12d9a9d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoder and Full Autoencoder Model defined.\n"
          ]
        }
      ],
      "source": [
        "# Define the DECODER Network\n",
        "# Decompressed Layer 1 (Symmetrical to Encoder_L1)\n",
        "decoded = Dense(INTERMEDIATE_DIM, activation='relu', name='Decoder_L1')(latent_representation)\n",
        "\n",
        "# Output Layer (Must match the Input Dimension)\n",
        "output_layer = Dense(INPUT_DIM, activation='linear', name='Output_Reconstruction')(decoded)\n",
        "\n",
        "# ---------------------------------------\n",
        "\n",
        "# Create the Full Autoencoder Model\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer, name='Anomaly_Autoencoder')\n",
        "\n",
        "print(\"Decoder and Full Autoencoder Model defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZBQaKcY1qek"
      },
      "source": [
        "### **E. Compile the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "ud7mgPvk1hnZ",
        "outputId": "191c8224-2ad3-42b3-b96d-a4e6ad866d0e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Anomaly_Autoencoder\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"Anomaly_Autoencoder\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Input_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Encoder_L1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Latent_Representation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Decoder_L1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Reconstruction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">725</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Input_Layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Encoder_L1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Latent_Representation (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m350\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Decoder_L1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Reconstruction (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │           \u001b[38;5;34m725\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155</span> (8.42 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,155\u001b[0m (8.42 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155</span> (8.42 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,155\u001b[0m (8.42 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "autoencoder.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='mse', # Mean Squared Error is the metric for reconstruction quality\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display the model architecture\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjvxA68r1z0F"
      },
      "source": [
        "### **F. Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MN9bJpuK17Dv",
        "outputId": "3f241fad-0102-41c7-d789-23bd8eb565b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Autoencoder model training...\n",
            "Epoch 1/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3312 - loss: 0.5495 - val_accuracy: 0.4220 - val_loss: 0.3760\n",
            "Epoch 2/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 959us/step - accuracy: 0.4550 - loss: 0.3180 - val_accuracy: 0.4776 - val_loss: 0.2862\n",
            "Epoch 3/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4942 - loss: 0.2734 - val_accuracy: 0.5014 - val_loss: 0.2618\n",
            "Epoch 4/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5198 - loss: 0.2496 - val_accuracy: 0.5421 - val_loss: 0.2314\n",
            "Epoch 5/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5522 - loss: 0.2267 - val_accuracy: 0.5503 - val_loss: 0.2236\n",
            "Epoch 6/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5707 - loss: 0.2106 - val_accuracy: 0.5853 - val_loss: 0.2012\n",
            "Epoch 7/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5870 - loss: 0.1951 - val_accuracy: 0.5849 - val_loss: 0.1955\n",
            "Epoch 8/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5957 - loss: 0.1883 - val_accuracy: 0.5942 - val_loss: 0.1863\n",
            "Epoch 9/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985us/step - accuracy: 0.6001 - loss: 0.1849 - val_accuracy: 0.6056 - val_loss: 0.1841\n",
            "Epoch 10/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985us/step - accuracy: 0.6065 - loss: 0.1827 - val_accuracy: 0.6054 - val_loss: 0.1939\n",
            "Epoch 11/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6100 - loss: 0.1816 - val_accuracy: 0.6098 - val_loss: 0.1803\n",
            "Epoch 12/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 988us/step - accuracy: 0.6137 - loss: 0.1801 - val_accuracy: 0.6111 - val_loss: 0.1807\n",
            "Epoch 13/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6166 - loss: 0.1792 - val_accuracy: 0.6178 - val_loss: 0.1803\n",
            "Epoch 14/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6205 - loss: 0.1785 - val_accuracy: 0.6165 - val_loss: 0.1782\n",
            "Epoch 15/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6217 - loss: 0.1774 - val_accuracy: 0.6213 - val_loss: 0.1787\n",
            "Epoch 16/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 992us/step - accuracy: 0.6219 - loss: 0.1768 - val_accuracy: 0.6157 - val_loss: 0.1800\n",
            "Epoch 17/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6246 - loss: 0.1760 - val_accuracy: 0.6168 - val_loss: 0.1780\n",
            "Epoch 18/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 984us/step - accuracy: 0.6296 - loss: 0.1755 - val_accuracy: 0.6238 - val_loss: 0.1765\n",
            "Epoch 19/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 998us/step - accuracy: 0.6294 - loss: 0.1748 - val_accuracy: 0.6263 - val_loss: 0.1794\n",
            "Epoch 20/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978us/step - accuracy: 0.6288 - loss: 0.1741 - val_accuracy: 0.6277 - val_loss: 0.1756\n",
            "Autoencoder model training complete.\n"
          ]
        }
      ],
      "source": [
        "# Note that the input and output are identical (X_train_normal, X_train_normal), as the goal is self-reconstruction.\n",
        "\n",
        "print(\"\\nStarting Autoencoder model training...\")\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "H_auto = autoencoder.fit(\n",
        "    X_train_normal, X_train_normal,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_val_normal, X_val_normal),\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Autoencoder model training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl2nkyro2lYl"
      },
      "source": [
        "### **G. Calculate Reconstruction Error (Anomaly Score)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pToovLPsBF1K"
      },
      "source": [
        "Our **Autoencoder Model Predicts the features** (not target) given the features itself (It tries to reconstruct the input values as it is).\n",
        "\n",
        "**Error rates are low** (close to 0) when model reconstructs non-fraudulent transaction's features as it is familiar with these patterns (we train the model only on non-fraudulent data).\n",
        "\n",
        "**Fraud transactions have a larger error rate** as the model is not familiar with these patterns. (they are like 'out of syllabus' questions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nm_FF1U2S7l",
        "outputId": "ceb3c8c6-0446-4531-abd9-94e2bc0ba146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 424us/step\n"
          ]
        }
      ],
      "source": [
        "# Get reconstructions for the entire scaled dataset (normal and fraud)\n",
        "reconstructions = autoencoder.predict(X_scaled)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) for each transaction\n",
        "mse = np.mean(np.square(X_scaled - reconstructions), axis=1)\n",
        "\n",
        "# Store results in a DataFrame for easy analysis\n",
        "error_df = pd.DataFrame({\n",
        "    'Reconstruction_Error': mse,\n",
        "    'True_Class': y\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "00bd9627",
        "outputId": "ef311fb5-eb25-42f7-cdef-4a1dd775dc68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Reconstruction_Error  True_Class\n",
            "279863              5.796587           1\n",
            "280143              2.927265           1\n",
            "280149              2.940434           1\n",
            "281144              5.496614           1\n",
            "281674              0.042834           1\n",
            "\n",
            "\n",
            "        Reconstruction_Error  True_Class\n",
            "284802              0.230511           0\n",
            "284803              0.036120           0\n",
            "284804              0.006130           0\n",
            "284805              0.124024           0\n",
            "284806              0.061479           0\n"
          ]
        }
      ],
      "source": [
        "fraud_errors = error_df[error_df['True_Class'] == 1]\n",
        "normal_errors = error_df[error_df['True_Class'] == 0]\n",
        "\n",
        "print(fraud_errors.tail())\n",
        "print(\"\\n\")\n",
        "print(normal_errors.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUgCbICr3RcL"
      },
      "source": [
        "### **H. Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4hVYdKkAPGs"
      },
      "source": [
        "We find a **THRESHOLD** value for all the errors to be compared with.\n",
        "\n",
        "This is the **value which is greater than 95% of the error values** of all **non-fraudulent** transactions.\n",
        "\n",
        "This also means that all other transactions with **error > THRESHOLD** will be considered **FRAUD** (including 5% normal transactions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOJWxfzs3NMW",
        "outputId": "a4613adc-2c1d-4f82-ee2d-6f6818e776c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculated Anomaly Threshold: 0.459735\n"
          ]
        }
      ],
      "source": [
        "# Extract the normal (non-fraudulent) reconstruction errors\n",
        "normal_error = error_df[error_df['True_Class'] == 0].Reconstruction_Error\n",
        "\n",
        "# 1. Set Anomaly Threshold\n",
        "# Use the 95th percentile of the reconstruction error from NORMAL transactions\n",
        "THRESHOLD = np.percentile(normal_error, 95)\n",
        "print(f\"\\nCalculated Anomaly Threshold: {THRESHOLD:.6f}\")\n",
        "\n",
        "# 2. Predict anomalies for the entire dataset\n",
        "# The prediction is TRUE (1 or Fraud) if the error is above the threshold\n",
        "predicted_anomalies = error_df['Reconstruction_Error'] > THRESHOLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5eaT45WD-GO",
        "outputId": "97a0479f-d0fe-4a99-e497-a6b21cdb941d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix\n",
            "[[270099  14216]\n",
            " [    73    419]]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nConfusion Matrix\")\n",
        "print(confusion_matrix(error_df['True_Class'], predicted_anomalies))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxFzQ_MPDAyi",
        "outputId": "c9f05257-d2d7-47e2-e7be-79b9dc192e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 2.86%\n",
            "Recall: 85.16%\n"
          ]
        }
      ],
      "source": [
        "# Calculate and print Precision for the minority class (pos_label=1)\n",
        "precision = precision_score(error_df['True_Class'], predicted_anomalies, pos_label=1)\n",
        "print(f\"Precision: {100*precision:.2f}%\")\n",
        "\n",
        "# Calculate and print Recall for the minority class (pos_label=1)\n",
        "recall = recall_score(error_df['True_Class'], predicted_anomalies, pos_label=1)\n",
        "print(f\"Recall: {100*recall:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5KHtBHZHB1v"
      },
      "source": [
        "Here, the **main evaluation metric is Recall** and not Precision.\n",
        "\n",
        "High Recall indicates that higher number of Fraud transactions have been correctly flagged, which is the main goal."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JLj4F2-r1bGz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
